{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 10 мая 2021, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 10 мая, -4 балла после 08:30 17 мая, -6 баллов после 08:30 24 мая, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0221, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ваше решение тут:\n",
    "1) $ 2(y_i - a_{t-1}(x_i))$\n",
    "\n",
    "\n",
    "2) $ y_i exp( -a_{t-1}(x_i) y_i) $\n",
    "\n",
    "\n",
    "3) $ \\frac{y_i exp( -a_{t-1}(x_i) y_i)} {\\log (1 + exp( -a_{t-1}(x_i) y_i))}   $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class MyGradientBoostingClassifier():\n",
    "\n",
    "    def __init__(self, loss = 'MSE', learning_rate = 0.1, n_estimators = 5, colsample = 40, subsample = 50, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.models = []\n",
    "        self.features = []\n",
    "        self.init = 0\n",
    "        self.init_model = None\n",
    "    \n",
    "    def fit(self, X, y, base_model, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        if init_model is None:\n",
    "            self.init = y.mean()\n",
    "            f = [self.init] * y.shape[0]\n",
    "            f =  np.array(f)\n",
    "        else:\n",
    "            clf = init_model(*self.args, **self.kwargs)\n",
    "            clf.fit(X,y)\n",
    "            self.models.append(clf)\n",
    "            self.features.append(list(range(X.shape[1])))\n",
    "            f = np.array(clf.predict(X))\n",
    "            self.init_model = clf\n",
    "\n",
    "        for n in range(self.n_estimators):\n",
    "            num_of_features = list(range(X.shape[1]))\n",
    "            random.shuffle(num_of_features)\n",
    "            count_of_features = round(X.shape[1] * self.colsample / 100)\n",
    "            num_of_features = num_of_features[:count_of_features]\n",
    "            Xfeatures = X[:, num_of_features]\n",
    "            self.features.append(num_of_features)\n",
    "            \n",
    "            num_of_objects = list(range(X.shape[0]))\n",
    "            random.shuffle(num_of_objects)\n",
    "            count_of_objects = round(X.shape[0] * self.subsample / 100)\n",
    "            num_of_objects = num_of_objects[:count_of_objects]\n",
    "            X_subsample = Xfeatures[num_of_objects,:]\n",
    "            y_subsample = y[num_of_objects]\n",
    "            f_subsample = f[num_of_objects]\n",
    "            \n",
    "            if self.loss == 'MSE':\n",
    "                target = 2 * (y_subsample - f_subsample)\n",
    "            if self.loss == 'exp':\n",
    "                target =  y_subsample * np.exp(- y_subsample * f_subsample)\n",
    "            if self.loss == 'log':\n",
    "                target = y_subsample * np.exp(- y_subsample * f_subsample) / (1 + np.exp(- y_subsample * f_subsample))\n",
    "                \n",
    "            clf = base_model(*self.args, **self.kwargs)\n",
    "            clf.fit(X_subsample, target)\n",
    "            self.models.append(clf)\n",
    "            f = f + self.learning_rate * np.array(clf.predict(Xfeatures))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Ваш код здесь\n",
    "        if self.init != 0:\n",
    "            pred = np.array([self.init] * X.shape[0])\n",
    "        else:\n",
    "            pred = np.array(self.init_model.predict(X)).astype(float)\n",
    "        for n in range(self.n_estimators):\n",
    "            pred += self.learning_rate * self.models[n].predict(X[:, self.features[n]])\n",
    "        return  np.round(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train, base_model = DecisionTreeRegressor)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iter = [2, 5, 7, 10, 15, 20]\n",
    "accuracy = []\n",
    "for n in num_of_iter:\n",
    "    my_clf = MyGradientBoostingClassifier(n_estimators = n)\n",
    "    my_clf.fit(X_train, y_train, base_model = DecisionTreeRegressor)\n",
    "    accuracy.append(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Зависимость точности от числа итераций')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,axes = plt.subplots(1,1,figsize = (6,4))\n",
    "plt.plot(num_of_iter, accuracy, color='b')\n",
    "axes.set_xlabel(u'Число итераций',fontsize = 10)\n",
    "axes.set_ylabel(u'Точность',fontsize = 10)\n",
    "axes.set_title(u'Зависимость точности от числа итераций',fontsize = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Слегка редактируем исходный классификатор, чтобы положить в GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class MyGradientBoostingClassifier(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, loss = 'MSE', learning_rate = 0.1, n_estimators = 5, colsample = 40, subsample = 50):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        colsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        self.loss = loss\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        #self.args = args\n",
    "        #self.kwargs = kwargs\n",
    "        self.models = []\n",
    "        self.features = []\n",
    "        self.init = 0\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, base_model, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        # Ваш код здесь\n",
    "        if init_model is None:\n",
    "            self.init = y.mean()\n",
    "            f = [self.init] * y.shape[0]\n",
    "            f =  np.array(f)\n",
    "        else:\n",
    "            clf = init_model()\n",
    "            clf.fit(X,y)\n",
    "            self.models.append(clf)\n",
    "            self.features.append(list(range(X.shape[1])))\n",
    "            f = np.array(clf.predict(X))\n",
    "\n",
    "        for n in range(self.n_estimators):\n",
    "            num_of_features = list(range(X.shape[1]))\n",
    "            random.shuffle(num_of_features)\n",
    "            count_of_features = round(X.shape[1] * self.colsample / 100)\n",
    "            num_of_features = num_of_features[:count_of_features]\n",
    "            Xfeatures = X[:, num_of_features]\n",
    "            self.features.append(num_of_features)\n",
    "            \n",
    "            num_of_objects = list(range(X.shape[0]))\n",
    "            random.shuffle(num_of_objects)\n",
    "            count_of_objects = round(X.shape[0] * self.subsample / 100)\n",
    "            num_of_objects = num_of_objects[:count_of_objects]\n",
    "            X_subsample = Xfeatures[num_of_objects,:]\n",
    "            y_subsample = y[num_of_objects]\n",
    "            f_subsample = f[num_of_objects]\n",
    "            \n",
    "            if self.loss == 'MSE':\n",
    "                target = 2 * (y_subsample - f_subsample)\n",
    "            if self.loss == 'exp':\n",
    "                target =  y_subsample * np.exp(- y_subsample * f_subsample)\n",
    "            if self.loss == 'log':\n",
    "                target = y_subsample * np.exp(- y_subsample * f_subsample) / (1 + np.exp(- y_subsample * f_subsample))\n",
    "                \n",
    "            clf = base_model()\n",
    "            clf.fit(X_subsample, target)\n",
    "            self.models.append(clf)\n",
    "            f = f + self.learning_rate * np.array(clf.predict(Xfeatures))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # Ваш код здесь\n",
    "        pred = np.array([self.init] * X.shape[0])\n",
    "        for n in range(self.n_estimators):\n",
    "            pred += self.learning_rate * self.models[n].predict(X[:, self.features[n]])\n",
    "        return  np.round(pred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MyGradientBoostingClassifier(n_estimators=7),\n",
       "             param_grid={'colsample': [30, 40, 50, 60],\n",
       "                         'learning_rate': [0.05, 0.1, 0.15, 0.2],\n",
       "                         'loss': ['MSE', 'exp', 'log'],\n",
       "                         'subsample': [30, 40, 50, 60]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "loss = ['MSE', 'exp', 'log']\n",
    "learning_rate = [0.05, 0.1, 0.15, 0.2]\n",
    "colsample = [30, 40, 50, 60]\n",
    "subsample = [30, 40, 50, 60]\n",
    "clf = MyGradientBoostingClassifier(n_estimators = 7)\n",
    "searcher = GridSearchCV(clf, param_grid = {'loss': loss,'learning_rate': learning_rate, 'colsample': colsample, 'subsample': subsample},\n",
    "                        scoring='accuracy')\n",
    "\n",
    "searcher.fit(X_train, y_train, base_model = DecisionTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample': 60, 'learning_rate': 0.05, 'loss': 'log', 'subsample': 50}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8658475299421802"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss = 'log', colsample = 60, subsample= 50, learning_rate = 0.05, n_estimators = 7)\n",
    "my_clf.fit(X_train, y_train, base_model = RandomForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872093023255814\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Качество улучшилось, что видно даже без подборка по сетке. Случайный лес дает усложение модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837209302325582\n"
     ]
    }
   ],
   "source": [
    "pred = np.ones([X_test.shape[0]]) * y_train.mean()\n",
    "for n in range(20):\n",
    "    num_of_objects = list(range(X_train.shape[0]))\n",
    "    random.shuffle(num_of_objects)\n",
    "    count_of_objects = round(X.shape[0] * 50 / 100)\n",
    "    num_of_objects = num_of_objects[:count_of_objects]\n",
    "    X_subsample = X_train[num_of_objects,:]\n",
    "    y_subsample = y_train[num_of_objects]\n",
    "    my_clf = MyGradientBoostingClassifier(loss = 'log', colsample = 60, subsample= 50, learning_rate = 0.05, n_estimators = 7)\n",
    "    my_clf.fit(X_subsample, y_subsample, DecisionTreeRegressor)\n",
    "    pred += my_clf.predict(X_test)\n",
    "pred = np.round(pred / 20)\n",
    "print(accuracy_score(y_pred=pred, y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Аналогично качество улучшается. Так как модель усложняется. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8091085271317829\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss = 'log', colsample = 60, subsample= 50, learning_rate = 0.05, n_estimators = 7)\n",
    "my_clf.fit(X_train, y_train, DecisionTreeRegressor, init_model=linear_model.LogisticRegression)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8798449612403101\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss = 'log', colsample = 60, subsample= 50, learning_rate = 0.05, n_estimators = 7)\n",
    "my_clf.fit(X_train, y_train, DecisionTreeRegressor, init_model=RandomForestRegressor)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5876937984496124\n"
     ]
    }
   ],
   "source": [
    "my_clf = MyGradientBoostingClassifier(loss = 'log', colsample = 60, subsample= 50, learning_rate = 0.05, n_estimators = 7)\n",
    "my_clf.fit(X_train, y_train, DecisionTreeRegressor, init_model=SVC)\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество улучшается, но не на всех моделях. Возможно для улучшения нужно подбирать параметры для инициализирующей модели на валидации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
